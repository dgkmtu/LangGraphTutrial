{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nlrHY6Q-ntDM"
      },
      "outputs": [],
      "source": [
        "!pip install langchain==0.3.0 langchain-openai==0.2.0 langgraph==0.2.22"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# OpenAIのAPIキーを環境変数に設定（ハードコードは避けてください）\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_API_KEY\" # セキュリティのため実際は.envファイルなどが望ましい"
      ],
      "metadata": {
        "id": "yVBUqHx_nxP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import operator\n",
        "from typing import Annotated, Any\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field  # 状態モデル用\n",
        "from langgraph.graph import StateGraph, END  # グラフ構築用\n",
        "from langchain_openai import ChatOpenAI  # OpenAIのチャットモデル\n",
        "from langchain_core.runnables import ConfigurableField  # LLM設定変更用\n",
        "from langchain_core.prompts import ChatPromptTemplate  # プロンプトテンプレート\n",
        "from langchain_core.output_parsers import StrOutputParser  # LLMの文字列出力を扱う"
      ],
      "metadata": {
        "id": "X4eq4o36nzTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 回答ロールの定義（番号付き）\n",
        "ROLES = {\n",
        "\t\"1\": {\n",
        "\t\t\"name\": \"一般知識エキスパート\",\n",
        "\t\t\"description\": \"幅広い分野の一般的な質問に答える\",\n",
        "\t\t\"details\": \"幅広い分野の一般的な質問に対して、正確でわかりやすい回答を提供してください。\"\n",
        "\t},\n",
        "\t\"2\": {\n",
        "\t\t\"name\": \"生成AI製品エキスパート\",\n",
        "\t\t\"description\": \"生成AIや関連製品、技術に関する専門的な質問に答える\",\n",
        "\t\t\"details\": \"生成AIや関連製品、技術に関する専門的な質問に対して、最新の情報と深い洞察を提供してください。\"\n",
        "\t},\n",
        "\t\"3\": {\n",
        "\t\t\"name\": \"カウンセラー\",\n",
        "\t\t\"description\": \"個人的な悩みや心理的な問題に対してサポートを提供する\",\n",
        "\t\t\"details\": \"個人的な悩みや心理的な問題に対して、共感的で支援的な回答を提供し、可能であれば適切なアドバイスも行なってください。\"\n",
        "\t}\n",
        "}"
      ],
      "metadata": {
        "id": "4kgg-rL_n3yU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LangGraphに渡す状態の定義\n",
        "class State(BaseModel):\n",
        "\tquery: str = Field(..., description=\"ユーザーからの質問\")\n",
        "\tcurrent_role: str = Field(\n",
        "\t\tdefault=\"\", description=\"選定された回答ロール\"\n",
        "\t)\n",
        "\tmessages: Annotated[list[str], operator.add] = Field(\n",
        "\t\tdefault=[], description=\"回答履歴\"\n",
        "\t)\n",
        "\tcurrent_judge: bool = Field(\n",
        "\t\tdefault=False, description=\"品質チェックの結果\"\n",
        "\t)\n",
        "\tjudgment_reason: str = Field(\n",
        "\t\tdefault=\"\", description=\"品質チェックの判定理由\"\n",
        "\t)"
      ],
      "metadata": {
        "id": "VggxP7t3n7Ap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# OpenAIのチャットモデル（gpt-4o-mini）を初期化\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.0)\n",
        "llm = llm.configurable_fields(max_tokens=ConfigurableField(id='max_tokens'))"
      ],
      "metadata": {
        "id": "5OCh4sYZn-gf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ノード①：ロールの選定\n",
        "def selection_node(state: State) -> dict[str, Any]:\n",
        "\tquery = state.query\n",
        "\trole_options = \"\\n\".join([f\"{k}. {v['name']}: {v['description']}\" for k, v in ROLES.items()])\n",
        "\tprompt = ChatPromptTemplate.from_template(\n",
        "\"\"\"質問を分析し、最も適切な回答担当ロールを選択してください。\n",
        "\n",
        "選択肢:\n",
        "{role_options}\n",
        "\n",
        "回答は選択肢の番号（1、2、または3）のみを返してください。\n",
        "\n",
        "質問: {query}\n",
        "\"\"\".strip()\n",
        "\t)\n",
        "\n",
        "\t# max_tokens=1 に設定して、1文字（番号）のみ返すよう制限\n",
        "\tchain = prompt | llm.with_config(configurable=dict(max_tokens=1)) | StrOutputParser()\n",
        "\trole_number = chain.invoke({\"role_options\": role_options, \"query\": query})\n",
        "\n",
        "\tselected_role = ROLES[role_number.strip()][\"name\"]\n",
        "\treturn {\"current_role\": selected_role}"
      ],
      "metadata": {
        "id": "A-iJAyqgoCNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ノード②：ロールに応じた回答の生成\n",
        "def answering_node(state: State) -> dict[str, Any]:\n",
        "\tquery = state.query\n",
        "\trole = state.current_role\n",
        "\trole_details = \"\\n\".join([f\"- {v['name']}: {v['details']}\" for v in ROLES.values()])\n",
        "\tprompt = ChatPromptTemplate.from_template(\n",
        "\"\"\"あなたは{role}として回答してください。以下の質問に対して、あなたの役割に基づいた適切な回答を提供してください。\n",
        "\n",
        "役割の詳細:\n",
        "{role_details}\n",
        "\n",
        "質問: {query}\n",
        "\n",
        "回答:\"\"\".strip()\n",
        "\t)\n",
        "\tchain = prompt | llm |StrOutputParser()\n",
        "\tanswer = chain.invoke({\"role\": role, \"role_details\": role_details, \"query\": query})\n",
        "\n",
        "\treturn {\"messages\": [answer]}"
      ],
      "metadata": {
        "id": "iSeximuPoJEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 回答品質の評価スキーマ\n",
        "class Judgement(BaseModel):\n",
        "\tjudge: bool = Field(default=False, description=\"判定結果\")\n",
        "\treason: str = Field(default=\"\", description=\"判定理由\")"
      ],
      "metadata": {
        "id": "bg7YBSuQoL8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ノード③：品質チェック（OKなら終了、NGなら再実行）\n",
        "def check_node(state: State) -> dict[str, Any]:\n",
        "\tquery = state.query\n",
        "\tanswer = state.messages[-1]\n",
        "\tprompt = ChatPromptTemplate.from_template(\n",
        "\"\"\"以下の回答の品質をチェックし、問題がある場合は'False'、問題がない場合は'True'を回答してください。\n",
        "また、その判断理由も説明してください。\n",
        "\n",
        "ユーザーからの質問: {query}\n",
        "回答: {answer}\n",
        "\"\"\".strip()\n",
        "\t)\n",
        "\tchain = prompt | llm.with_structured_output(Judgement)\n",
        "\tresult: Judgement = chain.invoke({\"query\": query, \"answer\": answer})\n",
        "\n",
        "\treturn {\n",
        "\t\t\"current_judge\": result.judge,\n",
        "\t\t\"judgement_reason\": result.reason\n",
        "\t}\n"
      ],
      "metadata": {
        "id": "qIiMiWDOoOLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LangGraphグラフの構築\n",
        "workflow = StateGraph(State)\n",
        "\n",
        "# 各ノードをグラフに追加\n",
        "workflow.add_node(\"selection\", selection_node)\n",
        "workflow.add_node(\"answering\", answering_node)\n",
        "workflow.add_node(\"check\", check_node)\n",
        "\n",
        "# 処理開始点を指定（最初はロール選定から）\n",
        "workflow.set_entry_point(\"selection\")\n",
        "\n",
        "# 各ノード間の遷移（エッジ）を定義\n",
        "workflow.add_edge(\"selection\", \"answering\")\n",
        "workflow.add_edge(\"answering\", \"check\")\n",
        "\n",
        "# 条件分岐：checkノードの結果によって終了 or やり直し\n",
        "workflow.add_conditional_edges(\n",
        "\t\"check\",\n",
        "\tlambda state: state.current_judge, # Trueなら終了、Falseなら再実行\n",
        "\t{True: END, False: \"selection\"}\n",
        ")"
      ],
      "metadata": {
        "id": "jH2d3N-PoS6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# グラフの最終的なコンパイル（実行可能状態に）\n",
        "compiled = workflow.compile()\n",
        "\n",
        "# 初期状態としてユーザーの質問を与える\n",
        "initial_state = State(query=\"生成AIについて教えてください\")\n",
        "\n",
        "# 実行（LangGraphが自動でループや遷移を管理）\n",
        "result = compiled.invoke(initial_state)\n",
        "\n",
        "# 最終出力（最終回答メッセージ）\n",
        "print(result[\"messages\"][-1])"
      ],
      "metadata": {
        "id": "xNNDhfzboWYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install graphviz libgraphviz-dev pkg-config\n",
        "!pip install pygraphviz"
      ],
      "metadata": {
        "id": "GtGU-odQoZx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "Image(compiled.get_graph().draw_png())"
      ],
      "metadata": {
        "id": "2eAaOGiwobpx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PysltV19oybt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}