{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Do3oRsd1alpi"
      },
      "outputs": [],
      "source": [
        "!pip install chromadb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ne63TGfAZZlD"
      },
      "outputs": [],
      "source": [
        "!pip install -U langchain-community langchain langchain-openai langgraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FX09omtmUoQ_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_API_KEY\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rAQmd-PyU_l9"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "from langgraph.graph.message import add_messages\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.schema import Document\n",
        "from langchain_core.messages import HumanMessage\n",
        "from langchain_openai import ChatOpenAI\n",
        "from typing import TypedDict, Literal, Optional"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X91vSRFmVkwM"
      },
      "outputs": [],
      "source": [
        "class State(TypedDict):\n",
        "    input: str\n",
        "    intent: Optional[Literal[\"rag\", \"llm\"]]\n",
        "    response: Optional[str]\n",
        "    quality_ok: Optional[bool]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x9JHq6WNcJ_3"
      },
      "outputs": [],
      "source": [
        "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RSqSkAXoZIM-"
      },
      "outputs": [],
      "source": [
        "# 仮のドキュメント群（検索対象）\n",
        "docs = [\n",
        "    Document(page_content=\"LangGraphはLangChain製のLLM向けステートマシングラフライブラリです。\"),\n",
        "    Document(page_content=\"LangChainはマルチステップ処理を管理するためのフレームワークです。\"),\n",
        "    Document(page_content=\"RAGは検索と生成を組み合わせた手法です。\")\n",
        "]\n",
        "\n",
        "# 分割とベクトル化\n",
        "text_splitter = CharacterTextSplitter(chunk_size=100, chunk_overlap=0)\n",
        "split_docs = text_splitter.split_documents(docs)\n",
        "embedding = OpenAIEmbeddings()\n",
        "\n",
        "# Chromaによるインデックス作成\n",
        "vectorstore = Chroma.from_documents(split_docs, embedding)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8DH0_zElVvZf"
      },
      "outputs": [],
      "source": [
        "# ノード定義\n",
        "def classify_intent(state):\n",
        "  query = state[\"input\"]\n",
        "  if \"資料\" in query:\n",
        "    state[\"intent\"] = \"rag\"\n",
        "  else:\n",
        "    state[\"intent\"] = \"llm\"\n",
        "  return state\n",
        "\n",
        "def rag_node(state):\n",
        "  query = state[\"input\"]\n",
        "  retriever = vectorstore.as_retriever(search_kwargs={\"k\": 1})\n",
        "  retrieved_docs = retriever.invoke(query)\n",
        "  retrieved_text = retrieved_docs[0].page_content if retrieved_docs else \"該当する情報が見つかりませんでした。\"\n",
        "  return {\"response\": f\"[RAG] {retrieved_text}\"}\n",
        "\n",
        "def llm_node(state):\n",
        "  user_input = state.get(\"input\", \"\")\n",
        "\n",
        "  messages = [HumanMessage(content=user_input)]\n",
        "  response = llm.invoke(messages)\n",
        "  return {\"response\": response.content}\n",
        "\n",
        "def evaluate_answer(state):\n",
        "  resp = state[\"response\"]\n",
        "  if \" (\" in resp:\n",
        "    # 品質低いと見なす\n",
        "    state[\"quality_ok\"] = False\n",
        "  else:\n",
        "    state[\"quality_ok\"] = True\n",
        "  return state\n",
        "\n",
        "def loop_or_end(state):\n",
        "  return \"repeat\" if not state[\"quality_ok\"] else \"end\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwA_8cZWXL4a"
      },
      "outputs": [],
      "source": [
        "# --- グラフ構築 ---\n",
        "workflow = StateGraph(State)\n",
        "workflow.set_entry_point(\"classify\")\n",
        "workflow.add_node(\"classify\", RunnableLambda(classify_intent))\n",
        "workflow.add_node(\"rag\", RunnableLambda(rag_node))\n",
        "workflow.add_node(\"llm\", RunnableLambda(llm_node))\n",
        "workflow.add_node(\"evaluate\", RunnableLambda(evaluate_answer))\n",
        "\n",
        "# 分岐と遷移\n",
        "workflow.add_conditional_edges(\"classify\", lambda s: s[\"intent\"], {\n",
        "    \"rag\": \"rag\",\n",
        "    \"llm\": \"llm\"\n",
        "})\n",
        "workflow.add_edge(\"rag\", \"evaluate\")\n",
        "workflow.add_edge(\"llm\", \"evaluate\")\n",
        "workflow.add_conditional_edges(\"evaluate\", loop_or_end, {\n",
        "    \"classify\": \"classify\",\n",
        "    \"end\": END\n",
        "})\n",
        "\n",
        "app = workflow.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LvZ4K0LAYVMD"
      },
      "outputs": [],
      "source": [
        "input_state = {\"input\": \"資料をください\"}\n",
        "for s in app.stream(input_state):\n",
        "  print(s)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 必要なパッケージをインストール\n",
        "!apt-get install -y graphviz libgraphviz-dev pkg-config\n",
        "!pip install pygraphviz"
      ],
      "metadata": {
        "id": "nO2aqUaxfSx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "\n",
        "# グラフの描画\n",
        "Image(app.get_graph().draw_png())"
      ],
      "metadata": {
        "id": "Zr624t-8fXAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r6mOj2qGffYx"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}